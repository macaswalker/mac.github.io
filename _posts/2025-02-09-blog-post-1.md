---
title: 'Optimal Strategies for Last Man Standing'
date: 2025-02-09
permalink: /posts/2025/02/LMS/
tags:
  - Game Theory
  - Optimal Betting Strategies
  - Modelling
---

I am currently playing Last Man Standing with my group of friends. I have thought that there should be a mathematical treatment of this problem - it seems as though there _should_ be an optimal way of playing.

In my exploration around this topic, I found [this](https://www.danialdervovic.com/2018/05/13/last-man-standing.html). This is a beautiful analysis and one I am super impressed by. There is, however, one main gripe I have with this treatment. The assumption of this model is that we should want to stay in _as long as possible_, as opposed to staying in _for the longest_. 

# The Setup

1. **Teams**  
   - Let there be $n$ teams in the league, labeled $1, 2, \dots, n$.
   - Each team $j$ plays a match in each gameweek (GW) $i$. We will ignore the case of double gameweeks.

2. **Players**  
   - Let there be $M$ players in the game.
   - Each player pays an entry fee of $x$ and aims to be the “last man standing.”

3. **States**  
   - After each week $i$, a player is either “alive” (if their chosen team that week won) or “eliminated” (if that team drew or lost).
   - A minimal representation of the **state** from an individual player’s perspective includes:
     - The current week index $i$.
     - The set of teams this player has **already used** in previous weeks.

4. **Actions**  
   - At the beginning of each week $i$, every **surviving** player must **choose** exactly one team $j$ that they have not chosen before.
   - If that chosen team $j$ **wins** its match in week $i$, the player survives to week $i+1$. Otherwise, the player is eliminated.

5. **Winning Probabilities**  
   - Let $p_j^{(i)}$ denote the probability that **team** $j$ wins its match in **week** $i$.

6. **States**
   - Let $a_j^{(i)}$ be the action of picking team $j$ at GW $i$. 

Hence we may visualise the entire game through the below graphic. Each node through this graph is a team, with winning and losing teams coloured green and red respectively. Each edge between a node is a choice of team $j$ at GW $i+1$ from GW $i$.

![graphic for whole team](/images/file_tables.jpg){: .align-center width="500px"}

Hence, we want to successfully navigate through this graph, where after $k$ choices of team, only us remain. We wish our results to look like below:

![graphic for whole team](/images/graphic_notables.jpg){: .align-center width="500px"}

---

## 1. Dynamic Programming / Markov Decision Process (MDP) Formulation

Instead of pre-committing to a full permutation of teams, you can view the problem as a multi-stage decision process. In this formulation:

- **State**: A state at gameweek $i$ could include:
  - The current gameweek index $i$.
  - The set of teams you have already used.
  - Information about the number of surviving players and the teams that they have already picked.
  
- **Actions**: At each stage (gameweek), the action is to choose one of the remaining teams.
  
- **Transition**: The system transitions to the next state based on:
  - The match outcome for the team you selected, governed by the probability $p_j^{(i)}$ (and possibly the outcomes of matches for other players).
  - Updates to your available team pool (since you cannot pick a team twice).

- **Reward / Objective**:  
  - Reward of $(M-1)*x$ at the end of the game if you are the sole winner, with a negative payoff of $-x$ if you are not the winner.

The objective is to maximize the probability of eventually reaching a terminal state in which you are the only player remaining.
  
This dynamic programming approach (or MDP formulation) captures the sequential nature of the game and can incorporate the evolving state of the competition. However, the state space may be very large, so you might need to use approximate dynamic programming methods or simulation-based techniques.

---

## 2. Simulation and Bayesian Learning

Another alternative is to adopt a **simulation-based approach**:

- **Simulate the Competition**: Create a simulator that models match outcomes (using the probabilities ($p_j^{(i)}$) and the elimination process for all players.
  
- **Bayesian or Reinforcement Learning**: Use simulation to learn which sequences of picks tend to yield the highest probability of being the sole survivor. This could involve:
  - Bayesian updating of your beliefs about opponents’ strategies.
  - Reinforcement learning techniques (Q-learning) to evaluate the long-term benefits of each action.
  
This approach will require a hefty amount of nuanced work!

---
